{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg\n",
    "from psycopg import Cursor\n",
    "\n",
    "from secret import POSTGRES_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as db:\n",
    "    db.execute(\"DROP TABLE IF EXISTS region CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS submission CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS activity CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS value_type CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS pollutant CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS pollutant_category CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS sectoral_approach CASCADE\")\n",
    "    db.execute(\"DROP TABLE IF EXISTS sectoral_approach_activities CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as db:\n",
    "    for table in db.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\"):\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_ENCODING = 'UTF8'\n",
    "CSV_DELIMITER = ','\n",
    "CSV_QUOTE_CHAR = '\"'\n",
    "\n",
    "def import_sample_record(file_name: str, cursor: Cursor, table: str, primary_key: str, columns: str,\n",
    "                         convert_to_bool: set={}, convert_to_int: set={}, convert_to_float: set={},\n",
    "                         print_log: bool=False):\n",
    "    # Load currently present data, used to skip records that already exist below \n",
    "    current_data = pd.read_sql_table(table, POSTGRES_CONNECTION_STRING, index_col=primary_key)\n",
    "    \n",
    "    # Walk through csv file, add records as needed\n",
    "    with cursor.copy(f'COPY {table} {columns} FROM STDIN') as copy:\n",
    "        with open(file_name, 'r', encoding=CSV_ENCODING, newline='') as file:\n",
    "            for record in csv.DictReader(file, delimiter=CSV_DELIMITER, quotechar=CSV_QUOTE_CHAR, quoting=csv.QUOTE_NONNUMERIC):\n",
    "                if record[primary_key] not in current_data.index:\n",
    "                    \n",
    "                    # Convert types and handle empty values\n",
    "                    for key, value in record.items():\n",
    "                        if isinstance(value, str) and len(value) == 0:\n",
    "                            record[key] = None  # Replace empty values with NULL\n",
    "                        elif key in convert_to_bool:\n",
    "                            record[key] = value.lower() != 'false'\n",
    "                        elif key in convert_to_int:\n",
    "                            record[key] = int(value)\n",
    "                   \n",
    "                    copy.write_row(record.values())\n",
    "                    if print_log:\n",
    "                        print(f'Adding new record: {tuple(record.values())}')\n",
    "                elif print_log:\n",
    "                    print(f'Skipping existing record: {tuple(record.values())}')\n",
    "\n",
    "def import_sample_time_series(file_name: str, cursor: Cursor, print_log: bool=False):\n",
    "    with open(file_name, 'r', encoding=CSV_ENCODING, newline='') as file:\n",
    "        for row, time_series in enumerate(csv.DictReader(file, delimiter=CSV_DELIMITER, quotechar=CSV_QUOTE_CHAR, quoting=csv.QUOTE_NONNUMERIC)):\n",
    "            if print_log:\n",
    "                print(f\"Adding time series from row {row+2}: {time_series['region']}*{time_series['submission']}*{time_series['activity']}*{time_series['type']}*{time_series['pollutant']}\")\n",
    "            \n",
    "            crf_variable_id = None\n",
    "            if time_series.get('crf_variable', None) or None:\n",
    "                cursor.execute('SELECT id FROM crf_variable WHERE submission=%s and variable=%s', (time_series['submission'], time_series['crf_variable']))\n",
    "                crf_variable_id = cursor.fetchone()[0]\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO sectoral_approach (region_code, submission_id, value_type_short, pollutant_chemical,\n",
    "                                               fuel_id, product_id, species_id, scenario, crf_variable_id, confidential, unit) \n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    RETURNING id\n",
    "                \"\"\", (time_series['region'],\n",
    "                      time_series['submission'],\n",
    "                      time_series['type'],\n",
    "                      time_series.get('pollutant', None) or None,\n",
    "                      time_series.get('fuel', None) or None,\n",
    "                      time_series.get('product', None) or None,\n",
    "                      time_series.get('species', None) or None,\n",
    "                      time_series['scenario'],\n",
    "                      crf_variable_id,\n",
    "                      time_series['confidential'],\n",
    "                      time_series['unit']))\n",
    "            time_series_database_id = cursor.fetchone()[0]\n",
    "            \n",
    "            activities = []\n",
    "            for level, activity in enumerate(time_series['path'].split(',')):\n",
    "                activities += [(time_series_database_id, activity, level, time_series['path'].endswith(f',{activity}'))]\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO sectoral_approach_activities (time_series_id, activity_code, level, leaf) \n",
    "                    VALUES (%s, %s, %s, %s)\n",
    "                \"\"\", activities)\n",
    "            \n",
    "            values = []\n",
    "            for year in range(1990, 2050+1):\n",
    "                if str(year) in time_series.keys() and time_series[str(year)]:\n",
    "                    values += [(time_series_database_id,\n",
    "                                year,\n",
    "                                time_series[str(year)] if not isinstance(time_series[str(year)], str) else 0.0,\n",
    "                                time_series[str(year)] if isinstance(time_series[str(year)], str) else None)]\n",
    "            cursor.executemany(\"\"\"\n",
    "                INSERT INTO sectoral_approach_value (time_series_id, year, value, notation_key) \n",
    "                    VALUES (%s, %s, %s, %s)\n",
    "                \"\"\", values)\n",
    "                    \n",
    "def show_full_table(table: str, primary_key: str=None):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(pd.read_sql_table(table, POSTGRES_CONNECTION_STRING, index_col=primary_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE DIMENSION: Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS region (\n",
    "                code     text     PRIMARY KEY CHECK (char_length(code) >= 2),\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0),\n",
    "                part_of  text     NULL        REFERENCES region DEFAULT NULL)\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/regions.csv', cursor=cursor, table='region',\n",
    "                             primary_key='code', columns='(code, part_of, label_en, label_de, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        #show_full_table('region', 'code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE DIMENSION: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS submission (\n",
    "                id          text     PRIMARY KEY,\n",
    "                region_code text     NOT NULL REFERENCES region,\n",
    "                date        date     NOT NULL,\n",
    "                label_en    text     NOT NULL CHECK (char_length(label_en) > 0),\n",
    "                label_de    text     NULL     CHECK (char_length(label_de) > 0),\n",
    "                order_by    smallint NOT NULL CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/submissions.csv', cursor=cursor, table='submission',\n",
    "                             primary_key='id', columns='(id, region_code, label_en, label_de, date, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        #show_full_table('submission', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE DIMENSION: Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activity (\n",
    "                code          text     PRIMARY KEY CHECK (char_length(code) > 0),\n",
    "                label_en      text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de      text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                tree_label_en text     NULL        CHECK (char_length(tree_label_en) > 0),\n",
    "                tree_label_de text     NULL        CHECK (char_length(tree_label_de) > 0),\n",
    "                image_url     text     NULL,\n",
    "                order_by      smallint NOT NULL    CHECK (order_by >= 0),\n",
    "                part_of       text     NULL        REFERENCES activity)\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/activities.csv', cursor=cursor, table='activity',\n",
    "                             primary_key='code', columns='(code, part_of, label_en, label_de, tree_label_en, tree_label_de, image_url, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('activity', 'code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE DIMENSION: Value type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS value_type (\n",
    "                short    text     PRIMARY KEY CHECK (char_length(short) >= 2),\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/types.csv', cursor=cursor, table='value_type',\n",
    "                             primary_key='short', columns='(short, label_en, label_de, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('value_type', 'short')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE DIMENSION: Pollutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS pollutant_category (\n",
    "                name    text PRIMARY KEY,\n",
    "                comment text NOT NULL)\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO pollutant_category VALUES\n",
    "                ('GHG', 'Greenhouse gases'),\n",
    "                ('AP', 'Air pollutants'),\n",
    "                ('TSP', 'Dust and particles'),\n",
    "                ('HM', 'Heavy metals'),\n",
    "                ('POP', 'Persistent organic pollutants'),\n",
    "                ('Other', 'Other pollutants')\n",
    "            ON CONFLICT (name) DO NOTHING\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS pollutant (\n",
    "                chemical text     PRIMARY KEY CHECK (char_length(chemical) >= 2),\n",
    "                category text     NOT NULL    REFERENCES pollutant_category,\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/pollutants.csv', cursor=cursor, table='pollutant',\n",
    "                             primary_key='chemical', columns='(chemical, label_en, label_de, category, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('pollutant', 'chemical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA DIMENSION: Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fuel_category (\n",
    "                name text PRIMARY KEY)\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO fuel_category VALUES\n",
    "                ('GASEOUS'),\n",
    "                ('LIQUID'),\n",
    "                ('SOLID')\n",
    "            ON CONFLICT (name) DO NOTHING\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fuel (\n",
    "                id       text     PRIMARY KEY CHECK (char_length(id) >= 2),\n",
    "                fossil   boolean  NOT NULL,\n",
    "                category text     NOT NULL    REFERENCES fuel_category,\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/fuels.csv', cursor=cursor, table='fuel',\n",
    "                             primary_key='id', columns='(id, label_en, label_de, fossil, category, order_by)',\n",
    "                             convert_to_bool={'fossil'}, convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('fuel', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA DIMENSION: Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS product (\n",
    "                id       text     PRIMARY KEY CHECK (char_length(id) >= 2),\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/products.csv', cursor=cursor, table='product',\n",
    "                             primary_key='id', columns='(id, label_en, label_de, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('product', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA DIMENSION: Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS species (\n",
    "                id       text     PRIMARY KEY CHECK (char_length(id) >= 2),\n",
    "                label_en text     NOT NULL    CHECK (char_length(label_en) > 0),\n",
    "                label_de text     NULL        CHECK (char_length(label_de) > 0),\n",
    "                order_by smallint NOT NULL    CHECK (order_by >= 0))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/species.csv', cursor=cursor, table='species',\n",
    "                             primary_key='id', columns='(id, label_en, label_de, order_by)',\n",
    "                             convert_to_int={'order_by'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('species', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUXILIARY: CRF variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS crf_variable (\n",
    "                id         serial  PRIMARY KEY,\n",
    "                variable   text    NOT NULL,\n",
    "                submission text    NOT NULL REFERENCES submission,\n",
    "                category   text    NOT NULL REFERENCES activity,\n",
    "                export     boolean NOT NULL,\n",
    "                unit       text    NULL,\n",
    "                text       text    NULL,\n",
    "                name       text    NOT NULL,\n",
    "                commodity  text    NOT NULL,\n",
    "                source     text    NOT NULL,\n",
    "                target     text    NOT NULL,\n",
    "                option     text    NOT NULL,\n",
    "                method     text    NOT NULL,\n",
    "                activity   text    NOT NULL,\n",
    "                attribute  text    NOT NULL,\n",
    "                gas        text    NOT NULL,\n",
    "                UNIQUE (variable, submission))\n",
    "            \"\"\")\n",
    "        connection.commit()\n",
    "\n",
    "        import_sample_record(file_name='sample_data/crf_variables.csv', cursor=cursor, table='crf_variable',\n",
    "                             primary_key='id', columns='(id, submission, category, variable, unit, export, text, name, commodity, source, target, option, method, activity, attribute, gas)',\n",
    "                             convert_to_bool={'export'}, convert_to_int={'id'})\n",
    "        connection.commit()\n",
    "        \n",
    "        show_full_table('crf_variable', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE: Sectoral approach time series and time series values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # TODO Add check to prevent region_code <-> submission mismatch!\n",
    "        # TODO Add column for method: Tier 1, Tier 2, Model etc\n",
    "        # TODO Add column for EF type: Default, CS, Guidebook etc.\n",
    "        # cursor.execute(\"DROP TABLE IF EXISTS sectoral_approach CASCADE\")\n",
    "        # cursor.execute(\"DROP TABLE IF EXISTS sectoral_approach_activities CASCADE\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS sectoral_approach (\n",
    "                id                 serial  PRIMARY KEY,\n",
    "                region_code        text    NOT NULL REFERENCES region,  \n",
    "                submission_id      text    NOT NULL REFERENCES submission,\n",
    "                value_type_short   text    NOT NULL REFERENCES value_type,\n",
    "                pollutant_chemical text    NULL     REFERENCES pollutant,\n",
    "                fuel_id            text    NULL     REFERENCES fuel,\n",
    "                product_id         text    NULL     REFERENCES product,\n",
    "                species_id         text    NULL     REFERENCES species,\n",
    "                scenario           text    NOT NULL DEFAULT 'REF',\n",
    "                crf_variable_id    integer NULL     REFERENCES crf_variable,\n",
    "                confidential       boolean NOT NULL,\n",
    "                unit               text    NOT NULL)\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS sectoral_approach_activities (\n",
    "                id             serial   PRIMARY KEY,\n",
    "                time_series_id integer  NOT NULL REFERENCES sectoral_approach ON DELETE CASCADE,\n",
    "                activity_code  text     NOT NULL REFERENCES activity,\n",
    "                level          smallint NOT NULL CHECK (level >= 0),\n",
    "                leaf           boolean  NOT NULL,\n",
    "                UNIQUE (time_series_id, activity_code))\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        # cursor.execute(\"DROP TABLE IF EXISTS sectoral_approach_value CASCADE\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS notation_key (\n",
    "                key   text PRIMARY KEY,\n",
    "                label text NOT NULL)\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO notation_key VALUES\n",
    "                ('NE', 'Not Estimated'),\n",
    "                ('NA', 'Not Applicable'),\n",
    "                ('NO', 'Not Occuring'),\n",
    "                ('IE', 'Included Elsewhere'),\n",
    "                ('C', 'Confidential')\n",
    "            ON CONFLICT (key) DO NOTHING\n",
    "            \"\"\")\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS sectoral_approach_value (\n",
    "                time_series_id integer  NOT NULL REFERENCES sectoral_approach ON DELETE CASCADE,\n",
    "                year           smallint NOT NULL CHECK (year >= 0),\n",
    "                value          numeric  NOT NULL DEFAULT 0.0,\n",
    "                notation_key   text     NULL     REFERENCES notation_key,\n",
    "                UNIQUE (time_series_id, year))\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute('DELETE FROM sectoral_approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/germany.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/france.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/belgium.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/misc.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/1A3bii_iii_diesel.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/1A3c_rail.csv', cursor, print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(POSTGRES_CONNECTION_STRING) as connection:\n",
    "    with connection.cursor() as cursor:\n",
    "        import_sample_time_series('sample_data/time_series/1A3e_natural_gas_compressors.csv', cursor, print_log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
